{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c02f3b0-00e9-40c5-8362-9b7bc22ce36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 1: Import Libraries\n",
    "# ==============================================================================\n",
    "import wikipediaapi\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee05b09-0c66-48ef-a00c-c8bc3f955d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set.\n",
      "Seed Topic: Renaissance\n",
      "Crawl Depth: 2\n",
      "Page Limit (at depth 1): 100\n",
      "Output will be saved to: ../data/Renaissance_edges_depth_2.csv\n",
      "Seed Topic: Renaissance\n",
      "Data will be saved to: ../data/Renaissance_edges.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 2: Configuration - SET YOUR TOPIC HERE\n",
    "# ==============================================================================\n",
    "# --- CONFIGURATION ---\n",
    "# To analyze a different topic, change the variable below.\n",
    "# Note: Use the exact title from the Wikipedia URL (e.g. 'Data_science').\n",
    "SEED_TOPIC = 'Renaissance'\n",
    "\n",
    "# --- CRAWL PARAMETERS ---\n",
    "# DEPTH: How many layers to crawl.\n",
    "#   - Depth 1: Just the links on the SEED_TOPIC page.\n",
    "#   - Depth 2: The SEED_TOPIC, its links, AND all of their links.\n",
    "CRAWL_DEPTH = 2\n",
    "\n",
    "# LIMIT: To keep the crawl fast, we can limit how many pages we analyze at the first level.\n",
    "# Set to None to crawl all links (can be very slow!).\n",
    "# A limit of 100 is a good starting point.\n",
    "PAGE_LIMIT = 100\n",
    "\n",
    "# Define where the output file will be saved\n",
    "OUTPUT_FOLDER = '../data'\n",
    "FILE_NAME = f'{SEED_TOPIC}_edges_depth_{CRAWL_DEPTH}.csv'\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_FOLDER, FILE_NAME)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(\"Configuration set.\")\n",
    "print(f\"Seed Topic: {SEED_TOPIC}\")\n",
    "print(f\"Crawl Depth: {CRAWL_DEPTH}\")\n",
    "print(f\"Page Limit (at depth 1): {PAGE_LIMIT}\")\n",
    "print(f\"Output will be saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "# Define the path to save our data file\n",
    "OUTPUT_FOLDER = '../data'\n",
    "FILE_NAME = f'{SEED_TOPIC}_edges.csv'\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_FOLDER, FILE_NAME)\n",
    "\n",
    "# Create the data directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"Seed Topic: {SEED_TOPIC}\")\n",
    "print(f\"Data will be saved to: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794f8976-4046-43c1-bb8a-c8eb379473b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wikipedia API client initialized.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 3: Initialize the Wikipedia API\n",
    "# ==============================================================================\n",
    "# Initialize the Wikipedia API with a custom user agent\n",
    "# This is a good practice to identify your script to Wikipedia's servers.\n",
    "wiki_api = wikipediaapi.Wikipedia(\n",
    "    language='en',\n",
    "    user_agent='MyNetworkAnalysisProject/1.0 (pathmohd123@gmail.com)'\n",
    ")\n",
    "\n",
    "print(\"\\nWikipedia API client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7877db7b-787e-4341-a753-7d032990c4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Deep Crawl for 'Renaissance' ---\n",
      "Fetching links from Level 0 page: Renaissance\n",
      "Applying limit: processing first 100 links out of 2098.\n",
      "  [1/100] Fetching links from Level 1 page: \"Polish death camp\" controversy...\n",
      "  [2/100] Fetching links from Level 1 page: 1948 Palestine war...\n",
      "  [3/100] Fetching links from Level 1 page: 2,500-year celebration of the Persian Empire...\n",
      "  [4/100] Fetching links from Level 1 page: 2022 Russian invasion of Ukraine...\n",
      "  [5/100] Fetching links from Level 1 page: 20th-century Western painting...\n",
      "  [6/100] Fetching links from Level 1 page: A. L. Rowse...\n",
      "  [7/100] Fetching links from Level 1 page: ABCANZ Armies...\n",
      "  [8/100] Fetching links from Level 1 page: ANZUK...\n",
      "  [9/100] Fetching links from Level 1 page: ANZUS...\n",
      "  [10/100] Fetching links from Level 1 page: AUKUS...\n",
      "  [11/100] Fetching links from Level 1 page: AUSCANNZUKUS...\n",
      "  [12/100] Fetching links from Level 1 page: Abel Tasman...\n",
      "  [13/100] Fetching links from Level 1 page: Abolitionism...\n",
      "  [14/100] Fetching links from Level 1 page: Abraham Zacuto...\n",
      "  [15/100] Fetching links from Level 1 page: Abrahamic religions...\n",
      "  [16/100] Fetching links from Level 1 page: Absolute monarchy...\n",
      "  [17/100] Fetching links from Level 1 page: Absolute monarchy in France...\n",
      "  [18/100] Fetching links from Level 1 page: Absolutism (European history)...\n",
      "  [19/100] Fetching links from Level 1 page: Abstract art...\n",
      "  [20/100] Fetching links from Level 1 page: Abstract expressionism...\n",
      "  [21/100] Fetching links from Level 1 page: Abstraction-Création...\n",
      "  [22/100] Fetching links from Level 1 page: Academic art...\n",
      "  [23/100] Fetching links from Level 1 page: Accounting...\n",
      "  [24/100] Fetching links from Level 1 page: Action painting...\n",
      "  [25/100] Fetching links from Level 1 page: Adam style...\n",
      "  [26/100] Fetching links from Level 1 page: Adoration of the Magi...\n",
      "  [27/100] Fetching links from Level 1 page: Aegean art...\n",
      "  [28/100] Fetching links from Level 1 page: Aeropittura...\n",
      "  [29/100] Fetching links from Level 1 page: Aestheticism...\n",
      "  [30/100] Fetching links from Level 1 page: Aesthetics...\n",
      "  [31/100] Fetching links from Level 1 page: African-American art...\n",
      "  [32/100] Fetching links from Level 1 page: African-American history...\n",
      "  [33/100] Fetching links from Level 1 page: African diaspora...\n",
      "  [34/100] Fetching links from Level 1 page: African historiography...\n",
      "  [35/100] Fetching links from Level 1 page: Africanfuturism...\n",
      "  [36/100] Fetching links from Level 1 page: Afrofuturism...\n",
      "  [37/100] Fetching links from Level 1 page: Afterlife...\n",
      "  [38/100] Fetching links from Level 1 page: Aftermath of the Falklands War...\n",
      "  [39/100] Fetching links from Level 1 page: Aftermath of the Winter War...\n",
      "  [40/100] Fetching links from Level 1 page: Age of Discovery...\n",
      "  [41/100] Fetching links from Level 1 page: Age of Enlightenment...\n",
      "  [42/100] Fetching links from Level 1 page: Age of Revolution...\n",
      "  [43/100] Fetching links from Level 1 page: Ages of Man...\n",
      "  [44/100] Fetching links from Level 1 page: Agnosticism...\n",
      "  [45/100] Fetching links from Level 1 page: Akita ranga...\n",
      "  [46/100] Fetching links from Level 1 page: Al-Andalus...\n",
      "  [47/100] Fetching links from Level 1 page: Al-Nahda...\n",
      "  [48/100] Fetching links from Level 1 page: Albigensian Crusade...\n",
      "  [49/100] Fetching links from Level 1 page: Albrecht Dürer...\n",
      "  [50/100] Fetching links from Level 1 page: Alessandro Farnese (cardinal)...\n",
      "  [51/100] Fetching links from Level 1 page: Allen Debus...\n",
      "  [52/100] Fetching links from Level 1 page: Alltagsgeschichte...\n",
      "  [53/100] Fetching links from Level 1 page: Alphabet...\n",
      "  [54/100] Fetching links from Level 1 page: Alps...\n",
      "  [55/100] Fetching links from Level 1 page: Altermodern...\n",
      "  [56/100] Fetching links from Level 1 page: Amazonian pop art...\n",
      "  [57/100] Fetching links from Level 1 page: Ambrogio Lorenzetti...\n",
      "  [58/100] Fetching links from Level 1 page: American Barbizon school...\n",
      "  [59/100] Fetching links from Level 1 page: American English...\n",
      "  [60/100] Fetching links from Level 1 page: American Figurative Expressionism...\n",
      "  [61/100] Fetching links from Level 1 page: American Impressionism...\n",
      "  [62/100] Fetching links from Level 1 page: American Realism...\n",
      "  [63/100] Fetching links from Level 1 page: Amerigo Vespucci...\n",
      "  [64/100] Fetching links from Level 1 page: Amin al-Husseini...\n",
      "  [65/100] Fetching links from Level 1 page: Amsterdam Impressionism...\n",
      "  [66/100] Fetching links from Level 1 page: Analysis of Western European colonialism and colonization...\n",
      "  [67/100] Fetching links from Level 1 page: Analytic philosophy...\n",
      "  [68/100] Fetching links from Level 1 page: Anatomy...\n",
      "  [69/100] Fetching links from Level 1 page: Ancestral civilisation...\n",
      "  [70/100] Fetching links from Level 1 page: Ancien Régime...\n",
      "  [71/100] Fetching links from Level 1 page: Ancient Celtic religion...\n",
      "  [72/100] Fetching links from Level 1 page: Ancient Greece...\n",
      "  [73/100] Fetching links from Level 1 page: Ancient Greek...\n",
      "  [74/100] Fetching links from Level 1 page: Ancient Greek art...\n",
      "  [75/100] Fetching links from Level 1 page: Ancient Greek philosophy...\n",
      "  [76/100] Fetching links from Level 1 page: Ancient Roman philosophy...\n",
      "  [77/100] Fetching links from Level 1 page: Ancient Rome...\n",
      "  [78/100] Fetching links from Level 1 page: Ancient art...\n",
      "  [79/100] Fetching links from Level 1 page: Ancients (art group)...\n",
      "  [80/100] Fetching links from Level 1 page: Andrea Mantegna...\n",
      "  [81/100] Fetching links from Level 1 page: Andreas Vesalius...\n",
      "  [82/100] Fetching links from Level 1 page: András Hess...\n",
      "  [83/100] Fetching links from Level 1 page: André de Gouveia...\n",
      "  [84/100] Fetching links from Level 1 page: André de Resende...\n",
      "  [85/100] Fetching links from Level 1 page: Anglo-Japanese style...\n",
      "  [86/100] Fetching links from Level 1 page: Anglo-Portuguese Alliance...\n",
      "  [87/100] Fetching links from Level 1 page: Anglo-Saxon art...\n",
      "  [88/100] Fetching links from Level 1 page: Anglo-Saxon paganism...\n",
      "  [89/100] Fetching links from Level 1 page: Anglosphere...\n",
      "  [90/100] Fetching links from Level 1 page: Animal painter...\n",
      "  [91/100] Fetching links from Level 1 page: Annales school...\n",
      "  [92/100] Fetching links from Level 1 page: Annals...\n",
      "  [93/100] Fetching links from Level 1 page: Antarctica...\n",
      "  [94/100] Fetching links from Level 1 page: Anthropology...\n",
      "  [95/100] Fetching links from Level 1 page: Anti-Normanism...\n",
      "  [96/100] Fetching links from Level 1 page: Anti-art...\n",
      "  [97/100] Fetching links from Level 1 page: Antipodeans...\n",
      "  [98/100] Fetching links from Level 1 page: Antonio Bonfini...\n",
      "  [99/100] Fetching links from Level 1 page: Antonio da Sangallo the Younger...\n",
      "  [100/100] Fetching links from Level 1 page: Antonio de Cabezón...\n",
      "\n",
      "✅ Crawl complete. Found 67051 unique edges.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 4: Perform Deep Data Crawl\n",
    "# ==============================================================================\n",
    "print(f\"\\n--- Starting Deep Crawl for '{SEED_TOPIC}' ---\")\n",
    "\n",
    "# Use a set to store edges to avoid duplicates\n",
    "edges = set()\n",
    "\n",
    "# Fetch the starting page\n",
    "seed_page = wiki_api.page(SEED_TOPIC)\n",
    "\n",
    "if not seed_page.exists():\n",
    "    print(f\"Error: Seed page '{SEED_TOPIC}' does not exist.\")\n",
    "else:\n",
    "    print(f\"Fetching links from Level 0 page: {seed_page.title}\")\n",
    "    \n",
    "    # Get the first level of links\n",
    "    level_one_links = list(seed_page.links.values())\n",
    "    \n",
    "    # Apply the limit if it's set\n",
    "    if PAGE_LIMIT is not None:\n",
    "        print(f\"Applying limit: processing first {PAGE_LIMIT} links out of {len(level_one_links)}.\")\n",
    "        level_one_links = level_one_links[:PAGE_LIMIT]\n",
    "\n",
    "    # Process level one links (pages linked directly from the seed topic)\n",
    "    for i, linked_page in enumerate(level_one_links):\n",
    "        # Add the edge from the seed page to this linked page\n",
    "        if linked_page.namespace == 0: # Ensure it's a standard article\n",
    "            edges.add((seed_page.title, linked_page.title))\n",
    "        \n",
    "        # If depth is 2, go deeper and get links from this page\n",
    "        if CRAWL_DEPTH >= 2:\n",
    "            print(f\"  [{i+1}/{len(level_one_links)}] Fetching links from Level 1 page: {linked_page.title}...\")\n",
    "            try:\n",
    "                # Add a small delay to be polite to Wikipedia's servers\n",
    "                time.sleep(0.01)\n",
    "                \n",
    "                # Get all links from the current linked_page\n",
    "                level_two_links = linked_page.links\n",
    "                for sub_link_title in level_two_links:\n",
    "                    if level_two_links[sub_link_title].namespace == 0:\n",
    "                         edges.add((linked_page.title, sub_link_title))\n",
    "            except Exception as e:\n",
    "                print(f\"    Could not process page {linked_page.title}. Error: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Crawl complete. Found {len(edges)} unique edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb30ac3-b076-4ecc-9cfe-2fbf6b5fa93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved successfully to ../data/Renaissance_edges.csv\n",
      "\n",
      "--- First 5 links ---\n",
      "                     source                            target\n",
      "0  Ancient Roman philosophy                 Korean philosophy\n",
      "1  Ancient Greek philosophy  History of philosophy in Finland\n",
      "2                Al-Andalus                             Jizya\n",
      "3                Al-Andalus   Dictablanda of Dámaso Berenguer\n",
      "4              Afrofuturism               Compton Crook Award\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Cell 5: Save the Data to a CSV File\n",
    "# ==============================================================================\n",
    "if edges:\n",
    "    # Convert the set of edges to a list of dictionaries for the DataFrame\n",
    "    edge_list = [{'source': source, 'target': target} for source, target in edges]\n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    df_edges = pd.DataFrame(edge_list)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_edges.to_csv(OUTPUT_PATH, index=False)\n",
    "    \n",
    "    print(f\"\\nData saved successfully to {OUTPUT_PATH}\")\n",
    "    print(\"\\n--- First 5 links ---\")\n",
    "    print(df_edges.head())\n",
    "else:\n",
    "    print(\"\\nNo edges were collected. Nothing to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f2899d-2c50-4f8f-9cca-7d066a6b3ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67051, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f880c-431c-4c21-952f-b9bb0b6b7f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29497c6f-491b-4374-9d81-6488de703c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
